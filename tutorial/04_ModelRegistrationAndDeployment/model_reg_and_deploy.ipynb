{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Registration and Deployment with Azure Machine Learning\n",
    "\n",
    "This notebook demonstrates the end-to-end process of selecting, registering, and deploying a pneumonia detection model using Azure Machine Learning. After completing hyperparameter tuning, this notebook guides you through analyzing model performance, selecting the best model, registering it in the Azure ML model registry, deploying it as a real-time inference endpoint, and validating the deployment with actual X-ray images.\n",
    "\n",
    "## Setup Pre-requisites\n",
    "\n",
    "Before running this notebook, you should have:\n",
    "\n",
    "- An Azure Machine Learning workspace with appropriate permissions.\n",
    "- Completed the model training and hyperparameter tuning process (sweep job).\n",
    "- Access to the dataset for testing the deployed model.\n",
    "- The necessary Python packages installed.\n",
    "- Proper authentication configured for your Azure environment.\n",
    "\n",
    "## What You'll Do\n",
    "\n",
    "- **Analyze hyperparameter sweep results** - Review metrics from multiple training runs to identify the best-performing model configuration\n",
    "- **Register the optimal model** - Create a versioned model asset in the Azure ML model registry with proper metadata\n",
    "- **Deploy to a managed online endpoint** - Configure and deploy the model as a scalable REST API service on Azure\n",
    "- **Test model inference** - Validate the deployed endpoint by sending a real X-ray image and receiving predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from workshop_helpers.utils import get_unique_name\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient.from_config(credential)\n",
    "\n",
    "unique_name = get_unique_name(credential)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Hyperparameter Sweep Results\n",
    "\n",
    "This cell analyzes the results from our completed hyperparameter sweep, allowing us to identify the best-performing model configuration based on validation metrics. Hyperparameter tuning is a critical step in the machine learning workflow that helps optimize model performance by systematically searching through different parameter combinations. By collecting and analyzing the metrics from all completed trial runs, we can make an informed decision about which model configuration to register and deploy.\n",
    "\n",
    "The process involves:\n",
    "\n",
    "- **Retrieving sweep information**: Accessing a specific sweep job by name and getting its current status\n",
    "- **Collecting trial runs**: Fetching all individual experiment runs that were part of the hyperparameter sweep\n",
    "- **Setting up MLflow tracking**: Connecting to the Azure ML workspace's MLflow tracking server to access logged metrics\n",
    "- **Extracting performance metrics**: Gathering validation metrics from only the completed runs to ensure valid comparisons\n",
    "- **Ranking configurations**: Creating a sorted DataFrame that ranks model configurations based on validation AUC, with higher values indicating better performance\n",
    "\n",
    "Once this analysis is complete, we can identify the top-performing model configuration and use its parameters for the final model registration and deployment, ensuring we proceed with the most effective version of our pneumonia detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "sweep_job = \"teal_rose_2zh0jt4q39\"\n",
    "\n",
    "# Get the latest status of the sweep job\n",
    "returned_sweep_job = ml_client.jobs.get(name=sweep_job)\n",
    "\n",
    "# Get all the trial runs for this sweep job\n",
    "runs = ml_client.jobs.list(parent_job_name=sweep_job)\n",
    "\n",
    "# Set up MLflow tracking to access run metrics\n",
    "mlflow_tracking_uri = ml_client.workspaces.get(ml_client.workspace_name).mlflow_tracking_uri\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "\n",
    "# Collect metrics from completed runs\n",
    "sweep_results = []\n",
    "for run in runs:\n",
    "    if run.status != \"Completed\":\n",
    "        continue\n",
    "    sweep_results.append(mlflow.get_run(run_id=run.name).data.metrics)\n",
    "    sweep_results[-1][\"name\"] = run.name\n",
    "\n",
    "# Create a DataFrame with results and sort by validation AUC (higher is better)\n",
    "df = pd.DataFrame(sweep_results).sort_values(by=\"val_auc\", ascending=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Best Model in Azure Machine Learning\n",
    "\n",
    "This step transitions our best-performing model from an experiment artifact to an officially registered model in the Azure ML registry. Model registration is a pivotal moment in the ML lifecycle that bridges the gap between experimentation and production deployment. By registering the model, we create a centralized, versioned asset that becomes the foundation for deployment, enabling traceability, governance, and reproducibility throughout the model's lifecycle.\n",
    "\n",
    "The registration process involves:\n",
    "\n",
    "- **Best Model Selection**: Identifying the top-performing model from our hyperparameter sweep based on validation metrics (though in this case we also have a hardcoded option as backup)\n",
    "- **Artifact Location Reference**: Creating a reference to the MLflow model artifact produced during the training run\n",
    "- **Model Entity Creation**: Defining a Model object with:\n",
    "  - A unique name that includes a custom identifier for clear versioning\n",
    "  - The path to the MLflow model artifacts from the best training run\n",
    "  - A descriptive summary of the model's purpose and training data source\n",
    "  - The type specification as \"MLFLOW_MODEL\" to maintain compatibility with the MLflow format\n",
    "\n",
    "- **Version Management**: The `create_or_update` method ensures proper versioning if models with this name already exist\n",
    "\n",
    "Once registered, this model becomes a managed asset in the Azure ML registry that can be deployed to various targets, shared with other team members, and tracked for compliance and governance purposes. This registration serves as the bridge between the experimentation phase and the operationalization of our pneumonia detection solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "best_run_name = df.iloc[0][\"name\"]\n",
    "\n",
    "best_run = ml_client.jobs.get(name=best_run_name)\n",
    "model_dir = best_run.inputs[\"mlflow_model_dir\"]._to_job_input()\n",
    "\n",
    "# Create a model object referencing the output from your training job\n",
    "model = Model(\n",
    "    name=f\"pneumonia_detection_model-{unique_name}\",  # Choose a name for your model\n",
    "    path=f\"azureml://jobs/{best_run.name}/outputs/artifacts/paths/{model_dir}\",\n",
    "    description=\"Pneumonia detection model trained on RSNA dataset\",\n",
    "    type=AssetTypes.MLFLOW_MODEL  # This matches the output type from your job\n",
    ")\n",
    "\n",
    "# Register the model in your workspace\n",
    "run_model = ml_client.models.create_or_update(model)\n",
    "\n",
    "run_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model to a Managed Online Endpoint\n",
    "\n",
    "This critical step transforms our registered model into an operational web service, making it accessible for real-time inference through a secure REST API. Deployment is the bridge between a trained model and its real-world application, enabling other systems and users to interact with our pneumonia detection solution. By using Azure ML's managed online endpoints, we benefit from infrastructure management, scaling capabilities, and monitoring features that are essential for production-grade AI systems.\n",
    "\n",
    "The deployment process involves:\n",
    "\n",
    "- **Model Registration Confirmation**: Finalizing the model registration to ensure it's properly stored in the Azure ML model registry\n",
    "- **Endpoint Creation**: Establishing a unique, persistent URL endpoint that will host our model:\n",
    "  - Using a workshop-specific naming convention to ensure uniqueness\n",
    "  - Creating the infrastructure that will handle incoming requests\n",
    "- **Deployment Configuration**: Setting up the runtime environment for our model:\n",
    "  - Specifying a GPU-enabled compute instance (`Standard_NC6s_v3`) for optimal inference performance\n",
    "  - Configuring a single instance for handling the expected inference load\n",
    "  - Linking the deployment to our registered model through its unique identifier\n",
    "- **Traffic Allocation**: Configuring 100% of incoming traffic to route to our deployment, enabling immediate availability\n",
    "\n",
    "Once deployed, our pneumonia detection model becomes a live service that can accept and process X-ray images, returning predictions through a standardized API. This enables integration with various applications, from clinical decision support systems to research tools, fulfilling the ultimate goal of making our AI solution useful and accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import ManagedOnlineEndpoint, ManagedOnlineDeployment\n",
    "# Register the Model\n",
    "run_model = ml_client.models.create_or_update(run_model)\n",
    "\n",
    "\n",
    "endpoint_name = f\"workshop-{unique_name}\"\n",
    "\n",
    "# Create endpoint and deployment with the classification model\n",
    "endpoint = ManagedOnlineEndpoint(name=endpoint_name)\n",
    "print(endpoint_name)\n",
    "endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name=endpoint_name,\n",
    "    endpoint_name=endpoint.name,\n",
    "    model=run_model.id,\n",
    "    instance_type=\"Standard_NC6s_v3\",\n",
    "    instance_count=1,\n",
    ")\n",
    "deployment = ml_client.online_deployments.begin_create_or_update(deployment).result()\n",
    "endpoint.traffic = {deployment.name: 100}\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model Endpoint with Real Data\n",
    "\n",
    "This validation step completes our end-to-end workflow by testing our deployed model with actual patient X-ray data. Testing a deployed endpoint is an essential quality assurance measure that confirms our model is correctly accessible, properly processes inputs, and returns valid predictions in a production environment. By successfully executing this test, we verify that our pneumonia detection solution is ready for integration with clinical systems or other applications, ensuring the transition from development to production has been completed successfully.\n",
    "\n",
    "The testing process involves:\n",
    "\n",
    "- **Authentication**: Retrieving the endpoint's primary access key to establish secure communication\n",
    "- **Data Preparation Functions**:\n",
    "  - Creating a base64 encoding function to convert DICOM images into a format suitable for API transmission\n",
    "  - Implementing a payload formatter that structures the encoded image according to the expected API schema\n",
    "  - Building a request handler that manages the HTTP POST operation with proper authentication headers\n",
    "\n",
    "- **Test Execution**: Sending a DICOM file to our endpoint\n",
    "- **Result Verification**: Receiving and displaying the model's prediction response, confirming the deployed model can successfully process inputs and generate meaningful outputs\n",
    "\n",
    "This successful test provides confidence that our pneumonia detection model is properly deployed and functioning as expected in a production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "import requests\n",
    "\n",
    "key = ml_client.online_endpoints.get_keys(endpoint.name).primary_key\n",
    "\n",
    "def encode_file_to_base64(filepath):\n",
    "    \"\"\"\n",
    "    Read a file and convert it to base64 string.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the file\n",
    "        \n",
    "    Returns:\n",
    "        str: Base64 encoded string of the file\n",
    "    \"\"\"\n",
    "    with open(filepath, \"rb\") as file:\n",
    "        encoded_string = base64.b64encode(file.read()).decode(\"utf-8\")\n",
    "    return encoded_string\n",
    "\n",
    "def make_payload(image_path):\n",
    "    image_b64 = encode_file_to_base64(image_path)\n",
    "    data = {\n",
    "        \"input_data\": {\"columns\": [\"image\"], \"index\": [0], \"data\": [[image_b64]]},\n",
    "    }\n",
    "    return data\n",
    "\n",
    "def make_request(image):\n",
    "    payload = make_payload(image)\n",
    "\n",
    "    return requests.post(\n",
    "        endpoint.scoring_uri,\n",
    "        json=payload,\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {key}\",\n",
    "        },\n",
    "    ).json()\n",
    "\n",
    "filepath = \"/home/azureuser/data/rsna-pneumonia-detection-challenge/stage_2_train_images/fffec09e-8a4a-48b1-b33e-ab4890ccd136.dcm\"\n",
    "\n",
    "data = make_request(filepath)\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the content to add at the end of the notebook:\n",
    "\n",
    "## Custom Model Deployment with Your Own Scripts and Models\n",
    "\n",
    "While the automated MLflow-based deployment we've demonstrated provides a streamlined path to production, Azure Machine Learning also supports more customized deployment scenarios. You can deploy models trained outside of Azure ML, use custom inference logic, or integrate specialized pre/post-processing steps that your application requires.\n",
    "\n",
    "Key customization options include:\n",
    "\n",
    "- **Custom inference scripts**: Write your own `scoring.py` file to define exactly how your model loads and processes inputs\n",
    "- **External models**: Upload and register models trained with any framework or tool\n",
    "- **Custom environments**: Define precise container environments with the dependencies your model needs\n",
    "- **Traffic management**: Implement advanced patterns like blue-green deployments and canary releases\n",
    "- **Custom handlers**: Process specialized data formats or implement complex inference logic\n",
    "\n",
    "Here's an example of a more customized deployment approach that uses a custom scoring script:\n",
    "\n",
    "```python\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import ManagedOnlineEndpoint, ManagedOnlineDeployment, CodeConfiguration\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient.from_config(credential=credential)\n",
    "# Define path to a local model directory\n",
    "local_model_path = \"./custom_model_files\"  # Adjust to your model location\n",
    "\n",
    "# Upload and register a custom model\n",
    "custom_model = Model(\n",
    "    name=\"my_model\",  # This name is referenced in the deployment code below\n",
    "    path=local_model_path,\n",
    "    description=\"Custom pneumonia detection model\",\n",
    "    type=AssetTypes.CUSTOM_MODEL  # For models not using MLflow format\n",
    ")\n",
    "\n",
    "# Register the model in your workspace\n",
    "registered_model = ml_client.models.create_or_update(custom_model)\n",
    "print(f\"Model registered: {registered_model.name}, version: {registered_model.version}\")\n",
    "# Step 1: Create (or update) an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=\"my-model-endpoint\",\n",
    "    description=\"Endpoint for model inference\"\n",
    ")\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "print(\"Endpoint created or updated:\", endpoint.name)\n",
    "\n",
    "# Step 2: Create (or update) an online deployment\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=endpoint.name,\n",
    "    model=ml_client.models.get(\"my_model\", label=\"latest\"),\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"src/\",  # Folder containing your scoring.py file\n",
    "        scoring_script=\"scoring.py\"\n",
    "    ),\n",
    "    environment=\"your_environment_name\",\n",
    "    instance_type=\"Standard_DS3_v2\",\n",
    "    instance_count=1\n",
    ")\n",
    "ml_client.online_deployments.begin_create_or_update(deployment).result()\n",
    "print(\"Deployment completed. Endpoint is live.\")\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "The custom deployment approach allows for greater flexibility but requires more code. Your `scoring.py` file would typically include functions like:\n",
    "\n",
    "- `init()`: Loads your model when the container starts\n",
    "- `run(raw_data)`: Processes incoming requests, applies your model, and returns predictions\n",
    "\n",
    "This approach is particularly valuable when:\n",
    "- Your model uses a framework not fully supported by MLflow\n",
    "- You need custom pre/post-processing logic\n",
    "- You want to deploy multiple models in the same endpoint\n",
    "- You need to integrate with external systems during inference\n",
    "\n",
    "Custom deployments give you full control over the inference process while still leveraging Azure ML's managed infrastructure for scaling, monitoring, and security."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
