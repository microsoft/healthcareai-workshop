{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Azure ML\n",
    "\n",
    "Azure Machine Learning (Azure ML) provides a robust platform for training machine learning models at scale. This notebook guides you through the process of configuring and submitting a training job to Azure ML's managed compute resources, allowing you to leverage powerful GPU instances without managing the underlying infrastructure.\n",
    "\n",
    "This notebook demonstrates how to submit a training job to Azure ML using the Python SDK. The job will:\n",
    "- Train a pneumonia detection model using PyTorch\n",
    "- Run on GPU compute for accelerated training\n",
    "- Leverage the registered RSNA pneumonia dataset\n",
    "- Use custom training parameters (epochs, learning rate)\n",
    "- Track metrics and artifacts automatically with MLflow\n",
    "\n",
    "By defining your training as an Azure ML job, you gain several advantages over running locally. Your experiments are automatically tracked, resources are provisioned on-demand, and your training can scale to multiple GPUs if needed. The job definition includes everything needed to reproduce your training, from code and data to environment configuration and compute resources.\n",
    "\n",
    "Once your job is submitted, you can monitor its progress through logs, metrics, and the Azure ML Studio interface. After training completes, the resulting model will be registered and can be deployed for inference or used in subsequent workflows.\n",
    "\n",
    "## Setup Pre-requisites\n",
    "\n",
    "Before starting, ensure you have the following ready:\n",
    "\n",
    "* You need access to an Azure ML workspace with appropriate permissions.\n",
    "* The RSNA pneumonia detection dataset should already be registered in your workspace.\n",
    "* Your Azure ML workspace should have quota for GPU compute resources.\n",
    "\n",
    "This notebook assumes you've already completed the data preparation steps and have registered your dataset with Azure ML. We'll be using that registered dataset as input to our training job, making it available to our compute cluster during training.\n",
    "\n",
    "## What you will do:\n",
    "\n",
    "* Connect to your Azure ML workspace using the Python SDK.\n",
    "* Set up GPU compute resources for model training.\n",
    "* Create and register a GPU-enabled environment with PyTorch.\n",
    "* Retrieve the RSNA pneumonia detection dataset from your workspace.\n",
    "* Configure and submit a distributed training job to Azure ML.\n",
    "* Monitor the training job's progress through the Azure ML Studio.\n",
    "\n",
    "The Azure ML Python SDK v2 simplifies these tasks through a streamlined interface, allowing you to focus on model development rather than infrastructure management. Throughout this notebook, you'll learn how to use key SDK components to orchestrate your training workflow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validicating credential....\n",
      "Credential Validated\n",
      "Determining unique name....\n",
      "Unique name: jmerkow\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from workshop_helpers.utils import get_unique_name\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient.from_config(credential)\n",
    "\n",
    "unique_name = get_unique_name(credential)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Compute Target Setup\n",
    "\n",
    "This cell configures a dedicated GPU compute environment for our machine learning training jobs. GPU acceleration is essential for efficiently training deep learning models, especially for computer vision tasks that require significant computational power. By establishing this compute target, we ensure our training pipeline has access to the necessary GPU resources without manually managing infrastructure.\n",
    "\n",
    "The code performs a critical infrastructure step that:\n",
    "\n",
    "- **Automates resource provisioning**: Eliminates the need for manual cluster creation through the Azure portal\n",
    "- **Enables scalability**: Configures auto-scaling to optimize resource usage during training\n",
    "- **Standardizes the environment**: Ensures all training jobs run on consistent, reproducible hardware\n",
    "- **Supports cost management**: Sets minimum instances to zero to avoid charges when the cluster is idle\n",
    "\n",
    "Steps:\n",
    "- Check if a GPU compute cluster named \"gpucluster\" already exists\n",
    "- If not found, create a new compute target with:\n",
    "  - GPU-enabled VM size (Standard_NC6s_v3)\n",
    "  - Auto-scaling configuration (0 minimum to 4 maximum instances)\n",
    "- Wait for cluster creation to complete\n",
    "- Log status of the compute resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing GPU compute cluster: gpucluster-jmerkow\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "gpu_cluster_name = f\"gpucluster-{unique_name}\" ## TODO Add unique name\n",
    "try:\n",
    "    compute_target = ml_client.compute.get(gpu_cluster_name)\n",
    "    print(f\"Using existing GPU compute cluster: {gpu_cluster_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Creating new GPU compute cluster: {gpu_cluster_name}\")\n",
    "    compute_target = AmlCompute(\n",
    "        name=gpu_cluster_name,\n",
    "        size=\"Standard_NC6s_v3\",  # GPU-enabled VM size, adjust if needed\n",
    "        min_instances=0,\n",
    "        max_instances=5,\n",
    "    )\n",
    "    ml_client.compute.begin_create_or_update(compute_target).result()\n",
    "    print(f\"Created GPU compute cluster: {gpu_cluster_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Environment Configuration\n",
    "\n",
    "This cell defines and registers a specialized GPU-enabled environment that will be used to execute our training code in the cloud. The environment configuration is a critical component of our machine learning workflow as it ensures all dependencies, frameworks, and GPU drivers are consistently available across training runs.\n",
    "\n",
    "By creating a dedicated environment with PyTorch and CUDA support, we establish a reproducible foundation that:\n",
    "\n",
    "- **Guarantees compatibility**: The curated Docker image provides pre-tested PyTorch with CUDA drivers that are optimized for deep learning\n",
    "- **Maintains consistency**: Environment versioning ensures all experiments run with identical dependencies\n",
    "- **Enables reproducibility**: The combination of the base image and conda file creates a fully documented, reusable environment\n",
    "- **Optimizes performance**: The environment is specifically configured to leverage GPU acceleration for faster model training\n",
    "\n",
    "Steps:\n",
    "- Define a GPU-enabled environment using a PyTorch/CUDA Docker image\n",
    "- Incorporate additional dependencies from a conda YAML file\n",
    "- Add metadata tags for environment categorization\n",
    "- Register the environment in the Azure ML workspace\n",
    "- Capture the environment name and version for reference in training jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered environment: uw-workshop-gpu-env-jmerkow:12\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "# This assumes you have an 'environment.yaml' in your code folder that defines your Conda dependencies.\n",
    "gpu_environment = Environment(\n",
    "    name=f\"uw-workshop-gpu-env-{unique_name}\",\n",
    "    description=\"GPU enabled environment\",\n",
    "    image=\"mcr.microsoft.com/azureml/curated/acpt-pytorch-1.13-cuda11.7:latest\",\n",
    "    conda_file=\"src/environment.yml\",\n",
    "    tags={\"gpu\": \"true\"}\n",
    ")\n",
    "\n",
    "# Register or update the environment in your workspace.\n",
    "registered_env = ml_client.environments.create_or_update(gpu_environment)\n",
    "print(f\"Registered environment: {registered_env.name}:{registered_env.version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Retrieval\n",
    "\n",
    "This cell accesses our previously registered pneumonia dataset from the Azure ML workspace, ensuring our training job can reference the correct data assets. By retrieving the latest version of the dataset, we establish a connection to the centralized data resource that maintains consistency across all training runs and enables reproducibility of our experiments.\n",
    "\n",
    "Steps:\n",
    "- Specify the dataset name to retrieve\n",
    "- Fetch the latest version of the registered dataset from the Azure ML workspace\n",
    "- Confirm successful retrieval by displaying dataset name and version information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved dataset: rsna_pneumonia_dataset-jmerkow, version: 1\n"
     ]
    }
   ],
   "source": [
    "data_name = f\"rsna_pneumonia_dataset-{unique_name}\"\n",
    "\n",
    "# Retrieve the registered dataset\n",
    "registered_data = ml_client.data.get(name=data_name, label=\"latest\")\n",
    "print(f\"Retrieved dataset: {registered_data.name}, version: {registered_data.version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring and Submitting the Training Job\n",
    "\n",
    "This cell represents the culmination of our workflow setup, where we define and launch the actual machine learning training job in Azure ML. By configuring a fully parameterized job definition, we create a reproducible, scalable, and tracked training process that can run on cloud infrastructure without manual intervention.\n",
    "\n",
    "The job configuration brings together all previously established components:\n",
    "- **Input Data**: References our registered pneumonia dataset\n",
    "- **Hyperparameters**: Defines training parameters that control model behavior\n",
    "- **Compute Resources**: Utilizes our GPU cluster for accelerated training\n",
    "- **Environment**: Uses our custom PyTorch environment with all dependencies\n",
    "- **Code Assets**: Points to our training script within the source directory\n",
    "- **Output Management**: Configures MLflow tracking for experiment monitoring\n",
    "\n",
    "This approach offers several critical advantages:\n",
    "- **Reproducibility**: Every aspect of the training process is defined and versioned\n",
    "- **Scalability**: Jobs can be executed on powerful cloud infrastructure\n",
    "- **Separation of Concerns**: Code, data, compute, and parameters are managed independently\n",
    "- **Experiment Tracking**: Integration with MLflow captures metrics and artifacts automatically\n",
    "- **Workflow Automation**: The job can be incorporated into larger ML pipelines\n",
    "\n",
    "Steps:\n",
    "- Define job inputs including dataset path and hyperparameters\n",
    "- Configure a command job with:\n",
    "  - Source code location\n",
    "  - Execution command with parameterized inputs\n",
    "  - Compute target configuration\n",
    "  - Environment specification\n",
    "  - Experiment organization details\n",
    "- Submit the job to Azure ML for execution\n",
    "- Return the job object for tracking and monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job created with dataset input. Ready to submit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Warning: the provided asset name 'uw-workshop-gpu-env-jmerkow' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'uw-workshop-gpu-env-jmerkow' will not be used for anonymous registration\n",
      "\u001b[32mUploading src (0.03 MBs): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27907/27907 [00:00<00:00, 157737.17it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>workshop-jmerkow</td><td>honest_onion_54rs3rjg81</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/honest_onion_54rs3rjg81?wsid=/subscriptions/6c180dd2-1ec4-4fad-8ba8-1f2d8d67c129/resourcegroups/fmmg-mars-collab/workspaces/fmmg-mars-collab&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'name': 'honest_onion_54rs3rjg81', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/microsoft/uwisconsin-collab-workshop.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': '3547a4bc7d5346eadf2a31f3b1d99027f5f5bd21', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain', '_azureml.ClusterName': 'gpucluster-jmerkow', 'ContentSnapshotId': 'f4988829-8a7b-4e0a-bd31-1546135b26ec'}, 'print_as_yaml': False, 'id': '/subscriptions/6c180dd2-1ec4-4fad-8ba8-1f2d8d67c129/resourceGroups/fmmg-mars-collab/providers/Microsoft.MachineLearningServices/workspaces/fmmg-mars-collab/jobs/honest_onion_54rs3rjg81', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/jmerkow-cpu-uw/code/Users/jmerkow/UW Workshop/tutorial/03_Training', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7efe7c55a470>, 'serialize': <msrest.serialization.Serializer object at 0x7efe7c5848b0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <TraceLogger attr_dict (WARNING)>, 'display_name': 'test_job', 'experiment_name': 'workshop-jmerkow', 'compute': 'gpucluster-jmerkow', 'services': {'Tracking': {'endpoint': 'azureml://westus2.api.azureml.ms/mlflow/v1.0/subscriptions/6c180dd2-1ec4-4fad-8ba8-1f2d8d67c129/resourceGroups/fmmg-mars-collab/providers/Microsoft.MachineLearningServices/workspaces/fmmg-mars-collab?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/honest_onion_54rs3rjg81?wsid=/subscriptions/6c180dd2-1ec4-4fad-8ba8-1f2d8d67c129/resourcegroups/fmmg-mars-collab/workspaces/fmmg-mars-collab&tid=72f988bf-86f1-41af-91ab-2d7cd011db47', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'data_dir': {'type': 'uri_folder', 'path': 'azureml://subscriptions/6c180dd2-1ec4-4fad-8ba8-1f2d8d67c129/resourcegroups/fmmg-mars-collab/workspaces/fmmg-mars-collab/datastores/workspaceblobstore/paths/LocalUpload/e41c3f0a32f2821262206fe3d1dae3c5/rsna-pneumonia-detection-challenge/', 'mode': 'ro_mount'}, 'max_epochs': '3', 'learning_rate': '0.001', 'batch_size': '32', 'mlflow_model_dir': 'outputs/mlflow_model_dir'}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.honest_onion_54rs3rjg81', 'mode': 'rw_mount'}}, 'inputs': {'data_dir': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7efe7c584be0>, 'max_epochs': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7efe7c584310>, 'learning_rate': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7efe7c5852d0>, 'batch_size': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7efe7c5850c0>, 'mlflow_model_dir': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7efe7c584820>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7efe7c5847f0>}, 'component': CommandComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'honest_onion_54rs3rjg81', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/jmerkow-cpu-uw/code/Users/jmerkow/UW Workshop/tutorial/03_Training', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7efe7c55a470>, 'serialize': <msrest.serialization.Serializer object at 0x7efe7c585090>, 'command': 'python train.py --data_dir ${{inputs.data_dir}} --max_epochs ${{inputs.max_epochs}} --learning_rate ${{inputs.learning_rate}} --batch_size ${{inputs.batch_size}} --mlflow_model_dir ${{inputs.mlflow_model_dir}}', 'code': '/subscriptions/6c180dd2-1ec4-4fad-8ba8-1f2d8d67c129/resourceGroups/fmmg-mars-collab/providers/Microsoft.MachineLearningServices/workspaces/fmmg-mars-collab/codes/21976e1f-32fd-43a7-8ad8-5ab416d71d24/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/6c180dd2-1ec4-4fad-8ba8-1f2d8d67c129/resourceGroups/fmmg-mars-collab/providers/Microsoft.MachineLearningServices/workspaces/fmmg-mars-collab/environments/uw-workshop-gpu-env-jmerkow/versions/12', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'schema': None, 'type': 'command', 'display_name': 'test_job', 'is_deterministic': True, 'inputs': {'data_dir': {'type': 'uri_folder', 'path': 'azureml://subscriptions/6c180dd2-1ec4-4fad-8ba8-1f2d8d67c129/resourcegroups/fmmg-mars-collab/workspaces/fmmg-mars-collab/datastores/workspaceblobstore/paths/LocalUpload/e41c3f0a32f2821262206fe3d1dae3c5/rsna-pneumonia-detection-challenge/', 'mode': 'ro_mount'}, 'max_epochs': {'type': 'string', 'default': '3'}, 'learning_rate': {'type': 'string', 'default': '0.001'}, 'batch_size': {'type': 'string', 'default': '32'}, 'mlflow_model_dir': {'type': 'string', 'default': 'outputs/mlflow_model_dir'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.honest_onion_54rs3rjg81', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://westus2.api.azureml.ms/mlflow/v1.0/subscriptions/6c180dd2-1ec4-4fad-8ba8-1f2d8d67c129/resourceGroups/fmmg-mars-collab/providers/Microsoft.MachineLearningServices/workspaces/fmmg-mars-collab?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/honest_onion_54rs3rjg81?wsid=/subscriptions/6c180dd2-1ec4-4fad-8ba8-1f2d8d67c129/resourcegroups/fmmg-mars-collab/workspaces/fmmg-mars-collab&tid=72f988bf-86f1-41af-91ab-2d7cd011db47', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7efe7c55a470>}, 'instance_id': 'ba277e21-1d2c-4756-b488-6ca805678a32', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'uw-workshop-gpu-env-jmerkow:12', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml import command, Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# Define job inputs including dataset and training hyperparameters\n",
    "inputs = {\n",
    "    \"data_dir\": Input(type=AssetTypes.URI_FOLDER, path=registered_data.path),  # Reference to pneumonia dataset\n",
    "    \"max_epochs\": 1,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 32,\n",
    "\n",
    "    \"mlflow_model_dir\": \"outputs/mlflow_model_dir\"  # Location to store MLflow model\n",
    "    }\n",
    "\n",
    "# Configure the training job with code, compute, and environment\n",
    "job = command(\n",
    "    code=\"./src\",  # Source code directory containing training script\n",
    "    command=\"python train.py --data_dir ${{inputs.data_dir}} --max_epochs ${{inputs.max_epochs}} --learning_rate ${{inputs.learning_rate}} --batch_size ${{inputs.batch_size}} --mlflow_model_dir ${{inputs.mlflow_model_dir}}\",\n",
    "    compute=gpu_cluster_name,  # Use the GPU cluster defined earlier\n",
    "    environment=registered_env,  # Use PyTorch GPU environment with dependencies\n",
    "    inputs=inputs,\n",
    "    experiment_name=f\"workshop-{unique_name}\",  # For organizing related jobs in AzureML\n",
    "    display_name=\"test_job\"  # Human-readable name in the AzureML UI\n",
    ")\n",
    "\n",
    "print(\"Job created with dataset input. Ready to submit.\")\n",
    "# Submit the job to AzureML and get a reference to the running job\n",
    "test_job = ml_client.jobs.create_or_update(job)\n",
    "test_job\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Output Streaming\n",
    "\n",
    "This cell connects to the running training job and displays its logs in real-time, allowing us to monitor progress, track metrics, and detect any issues as they occur without leaving the notebook environment.\n",
    "\n",
    "**_Note_: This cell will not complete until the job finishes execution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: honest_onion_54rs3rjg81\n",
      "Web View: https://ml.azure.com/runs/honest_onion_54rs3rjg81?wsid=/subscriptions/6c180dd2-1ec4-4fad-8ba8-1f2d8d67c129/resourcegroups/fmmg-mars-collab/workspaces/fmmg-mars-collab\n"
     ]
    },
    {
     "ename": "JobException",
     "evalue": "The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_job_ops_helper.py:272\u001b[0m, in \u001b[0;36mstream_logs_until_completion\u001b[0;34m(run_operations, job_resource, datastore_operations, raise_exception_on_failed_job, requests_pipeline)\u001b[0m\n\u001b[1;32m    271\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m--> 272\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_wait_before_polling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpoll_start_time\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m _current_details \u001b[38;5;241m=\u001b[39m run_operations\u001b[38;5;241m.\u001b[39mget_run_details(job_name)  \u001b[38;5;66;03m# TODO use FileWatcher\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mJobException\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:94\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:289\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mspan():\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[1;32m    287\u001b[0m             logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[1;32m    288\u001b[0m         ):\n\u001b[0;32m--> 289\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage_logger\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:818\u001b[0m, in \u001b[0;36mJobOperations.stream\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pipeline_child_job(job_object):\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineChildJobError(job_id\u001b[38;5;241m=\u001b[39mjob_object\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m--> 818\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_logs_until_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_runs_operations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datastore_operations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequests_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requests_pipeline\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_job_ops_helper.py:350\u001b[0m, in \u001b[0;36mstream_logs_until_completion\u001b[0;34m(run_operations, job_resource, datastore_operations, raise_exception_on_failed_job, requests_pipeline)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    344\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output streaming for the run interrupted.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBut the run is still executing on the compute target. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetails for canceling the run can be found here: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    348\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://aka.ms/aml-docs-cancel-run\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    349\u001b[0m     )\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JobException(\n\u001b[1;32m    351\u001b[0m         message\u001b[38;5;241m=\u001b[39merror_message,\n\u001b[1;32m    352\u001b[0m         target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mJOB,\n\u001b[1;32m    353\u001b[0m         no_personal_data_message\u001b[38;5;241m=\u001b[39merror_message,\n\u001b[1;32m    354\u001b[0m         error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mUSER_ERROR,\n\u001b[1;32m    355\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mJobException\u001b[0m: The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run"
     ]
    }
   ],
   "source": [
    "ml_client.jobs.stream(test_job.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization with Sweep Job\n",
    "\n",
    "This cell configures and launches an automated hyperparameter tuning experiment that systematically explores different learning rate values to optimize model performance. By leveraging Azure ML's sweep capabilities, we can efficiently discover optimal hyperparameters without manually testing each configuration.\n",
    "\n",
    "### Parameter Sweeps\n",
    "Parameter sweeps are essential in machine learning development for several key reasons:\n",
    "- **Objective optimization**: Automatically identifies parameter combinations that maximize model performance\n",
    "- **Efficient exploration**: LogUniform sampling efficiently explores values across orders of magnitude (10^-10 to 10^-2)\n",
    "- **Reduced human bias**: Systematic exploration may discover unintuitive but effective parameters humans might not try\n",
    "- **Time savings**: Parallel trials dramatically reduce the time needed to find optimal configurations\n",
    "- **Reproducibility**: The structured approach ensures the parameter search process is documented and repeatable\n",
    "\n",
    "In this specific sweep, we're exploring learning rate values, one of the most critical hyperparameters that influences convergence speed and final model quality.\n",
    "\n",
    "### Compute Clusters with AzureML\n",
    "Our sweep job leverages the GPU compute cluster we configured earlier, which provides several advantages:\n",
    "- **Resource elasticity**: Scales between 0-4 nodes as needed, maximizing resource utilization\n",
    "- **Parallel execution**: Runs multiple trials simultaneously, accelerating the optimization process\n",
    "- **Cost management**: Auto-scaling ensures we only pay for compute when actively using it\n",
    "- **Hardware optimization**: GPU acceleration dramatically speeds up each individual training run\n",
    "- **Centralized management**: All compute resources are managed through the AzureML platform\n",
    "\n",
    "Steps:\n",
    "- Create a new job configuration with a learning rate sweep parameter (LogUniform distribution from 10^-10 to 10^-2)\n",
    "- Configure sweep settings:\n",
    "  - Random sampling strategy to explore parameter space\n",
    "  - Maximum of 12 total trials with 3 running concurrently\n",
    "  - Early termination policy (Bandit) to automatically stop underperforming trials\n",
    "  - Target metric set to \"val_best_metric_val\" for maximization\n",
    "- Submit the sweep job for execution on our GPU cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import sweep\n",
    "\n",
    "command_for_sweep_job = job(learning_rate=sweep.LogUniform(-10, -2), max_epochs=20, batch_size=sweep.Choice([16, 32, 48]))\n",
    "command_for_sweep_job.display_name = None\n",
    "command_for_sweep_job.experiment_name = job.experiment_name\n",
    "sweep_job = command_for_sweep_job.sweep(\n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"val_best_metric_val\",\n",
    "    goal=\"Maximize\",\n",
    "    max_total_trials=12,\n",
    "    max_concurrent_trials=3,\n",
    "    early_termination_policy=sweep.BanditPolicy(\n",
    "        slack_factor=0.15, evaluation_interval=1, delay_evaluation=3\n",
    "    ))\n",
    "\n",
    "ml_client.jobs.create_or_update(sweep_job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
