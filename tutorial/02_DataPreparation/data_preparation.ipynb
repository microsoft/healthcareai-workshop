{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "Effective data preparation is foundational to successful machine learning models. This notebook guides you through preparing the RSNA Pneumonia Detection dataset for training, including data exploration, stratified splitting, visualization, and integration with Azure Machine Learning for streamlined model development.\n",
    "\n",
    "## What you will do:\n",
    "\n",
    "* Load and explore the dataset from the CSV file\n",
    "* Create stratified splits for training, validation, and testing\n",
    "* Visualize data distributions and image samples, including bounding boxes for positive cases\n",
    "* Register the dataset and related data assets with Azure Machine Learning\n",
    "\n",
    "Data preparation is critical for ensuring your models train on high-quality, properly organized data. Through this notebook, you'll learn essential techniques for processing medical imaging data and setting up a robust machine learning pipeline using Azure ML's data management capabilities.\n",
    "\n",
    "## Setup Pre-requisites\n",
    "\n",
    "Before starting, ensure you have the following ready:\n",
    "\n",
    "* Download the RSNA Pneumonia Detection dataset. It should be organized as follows:\n",
    "  - CSV file: `stage_2_train_labels.csv`\n",
    "  - DICOM images in the `stage_2_train_images` folder.\n",
    "* Make sure you have run `pip install -r requirements.txt` from the root directory.\n",
    "* Configure and authenticate with your Azure ML Workspace.\n",
    "\n",
    "The RSNA Pneumonia Detection dataset contains chest X-ray images with annotations indicating whether pneumonia is present and, if so, where in the image it appears. By properly preparing this dataset, you'll ensure your model can effectively learn the patterns that distinguish pneumonia cases from normal cases.\n",
    "\n",
    "## Download Data\n",
    "\n",
    "Go to the provided links to download the data. You can download directly to an AzureML compute with:\n",
    "```sh\n",
    "wget -O /home/azureuser/data/rsna-pneumonia-detection-challenge.zip '<url to zip>'\n",
    "```\n",
    "\n",
    "After you've downloaded the zip, extract it to `/home/azureuser/data/`:\n",
    "\n",
    "```bash\n",
    "unzip /home/azureuser/data/rsna-pneumonia-detection-challenge.zip -d /home/azureuser/data/rsna-pneumonia-detection-challenge\n",
    "ls -l /home/azureuser/data/rsna-pneumonia-detection-challenge\n",
    "```\n",
    "\n",
    "Once downloaded, we'll explore the dataset structure, create appropriate splits for model development, and register it with Azure ML to enable seamless access during training and evaluation phases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preview CSV Dataset\n",
    "\n",
    "This section begins our data preparation pipeline by loading the RSNA Pneumonia Detection Challenge dataset from the CSV file and performing initial examination. The CSV file contains critical information about each image, including patient IDs, class labels (pneumonia/normal), and bounding box coordinates for positive pneumonia cases.\n",
    "\n",
    "Understanding this tabular data is essential before proceeding with image processing, as it provides the ground truth annotations we'll need for model training. A thorough inspection of the dataset structure will help identify any potential issues such as missing values, class imbalance, or unexpected patterns.\n",
    "\n",
    "Steps:\n",
    "- Define the dataset directory path and locate the primary CSV file (`stage_2_train_labels.csv`)\n",
    "- Import the data into a pandas DataFrame for efficient manipulation and analysis\n",
    "- Display a random sample of rows to verify the data structure and contents\n",
    "- Examine key fields including `patientId`, `class`, and bounding box coordinates (`x`, `y`, `width`, `height`)\n",
    "- Confirm the data types and verify that no critical information is missing\n",
    "\n",
    "This initial exploration provides the foundation for subsequent data processing steps and helps determine appropriate strategies for data splitting and augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the local directory holding the dataset\n",
    "dataset_path = '/home/azureuser/data/rsna-pneumonia-detection-challenge/'\n",
    "\n",
    "csv_file = os.path.join(dataset_path, \"stage_2_train_labels.csv\")\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "df.sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Stratified Data Splits\n",
    "\n",
    "Splitting data appropriately is crucial for developing robust machine learning models, especially with medical imaging datasets where class imbalance is common. In this step, we'll create stratified splits to ensure that each subset maintains the same proportion of pneumonia-positive and pneumonia-negative cases as the original dataset.\n",
    "\n",
    "Stratification is particularly important for the RSNA dataset because:\n",
    "- It preserves the class distribution across all splits\n",
    "- It prevents validation and test sets from having statistically different distributions than training data\n",
    "- It ensures reliable model evaluation metrics, especially for imbalanced medical datasets\n",
    "\n",
    "Our approach follows best practices by creating:\n",
    "- A training set (70% of data) for model learning\n",
    "- A validation set (15% of data) for hyperparameter tuning and early stopping\n",
    "- A test set (15% of data) for final model evaluation\n",
    "\n",
    "Implementation steps:\n",
    "- First split the dataset into training (70%) and a temporary set (30%) using `train_test_split` with stratification on the `\"Target\"` column\n",
    "- Further divide the temporary set equally into validation and test sets, maintaining stratification\n",
    "- Verify that class distributions remain consistent across all three splits\n",
    "\n",
    "These carefully partitioned datasets will provide the foundation for training a model that generalizes well to unseen medical images while avoiding data leakage between the different phases of model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ext = \".dcm\"\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df[\"Target\"])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"Target\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Data Splits and Proportions\n",
    "\n",
    "Visualizing the distribution of our data splits is a critical quality assurance step in the machine learning pipeline. This visualization helps confirm that our stratification strategy has successfully maintained consistent class proportions across all datasets, which is essential for reliable model training and evaluation.\n",
    "\n",
    "With medical imaging data like the RSNA pneumonia dataset, even small imbalances in class distribution can significantly impact model performance and potentially lead to biased predictions. Our visualization will provide both numerical and graphical confirmation that our splits are properly balanced.\n",
    "\n",
    "Implementation steps:\n",
    "\n",
    "- **Compute Class Counts:** For each data split (Training, Validation, and Test), we'll count the occurrences of each target class (pneumonia vs. normal) and organize these counts in a structured DataFrame\n",
    "  \n",
    "- **Calculate Distribution Metrics:** We'll compute:\n",
    "  - Total samples in each split\n",
    "  - Proportion of positive and negative cases within each split (as percentages)\n",
    "  - Overall class distribution across the entire dataset\n",
    "  \n",
    "- **Create Visualization:** Generate a bar chart that clearly illustrates:\n",
    "  - Side-by-side comparison of class distributions across all three splits\n",
    "  - Color-coded representation of positive and negative cases\n",
    "  - Properly labeled axes and legend for clear interpretation\n",
    "\n",
    "- **Tabular Summary:** Display a comprehensive table showing both raw counts and percentages, providing a numerical reference alongside the visual representation\n",
    "\n",
    "This visualization serves as both documentation and validation that our dataset preparation maintains statistical integrity, establishing confidence in subsequent model development steps. Any significant deviation in class proportions would signal a need to revisit our splitting methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "df_counts = pd.DataFrame({\n",
    "    \"Train\": train_df[\"Target\"].value_counts(),\n",
    "    \"Val\": val_df[\"Target\"].value_counts(),\n",
    "    \"Test\": test_df[\"Target\"].value_counts()\n",
    "})\n",
    "\n",
    "df_counts.loc[\"Total\"] = [len(train_df), len(val_df), len(test_df)]\n",
    "\n",
    "df_percent = df_counts / df_counts.loc[\"Total\"]\n",
    "\n",
    "df_percent.plot(kind=\"bar\", ax=ax)\n",
    "ax.set_title(f\"Train (n={len(train_df)}), Val (n={len(val_df)}), Test (n={len(test_df)})\")\n",
    "ax.set_xlabel(\"Target\")\n",
    "ax.set_ylabel(\"Proportion\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "pd.concat([df_counts, df_percent], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Sample DICOM Images with Annotations\n",
    "\n",
    "Visualizing sample DICOM images with their corresponding annotations is a crucial step in medical imaging machine learning workflows. This visualization serves multiple purposes: it validates our data loading pipeline, confirms the accuracy of bounding box annotations, and provides clinical context for the machine learning task.\n",
    "\n",
    "DICOM (Digital Imaging and Communications in Medicine) is the standard format for medical imaging, containing both pixel data and rich metadata about the patient, acquisition parameters, and clinical context. Working with these specialized files requires careful handling to ensure proper interpretation of the radiological information.\n",
    "\n",
    "In this cell:\n",
    "\n",
    "- We select a diverse sample of 6 DICOM images from our training dataset, including both positive and negative pneumonia cases\n",
    "- Each image is loaded using the pydicom library, which preserves critical metadata while accessing the underlying pixel arrays\n",
    "- Images are displayed in grayscale, consistent with radiological practice for chest X-rays\n",
    "- For positive pneumonia cases, we overlay the ground truth bounding boxes that indicate the affected lung regions\n",
    "- The visualization is arranged in a grid format with patient IDs as titles for easy reference\n",
    "\n",
    "This visual inspection helps detect potential issues such as:\n",
    "- Incorrectly positioned or sized bounding boxes\n",
    "- Poor image quality or contrast that might affect model performance\n",
    "- Unusual anatomical presentations that may require special handling\n",
    "- Confirmation that our data loading pipeline correctly interprets the DICOM format\n",
    "\n",
    "Understanding these visual patterns is essential not only for technical validation but also for developing intuition about the clinical features that distinguish pneumonia cases from normal chest X-rays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "\n",
    "sample = train_df[:6]\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axs = axs.flatten()\n",
    "\n",
    "def draw_bounding_box(ax, x, y, width, height, edgecolor='red'):\n",
    "    if not any(pd.isnull([x, y, width, height])):\n",
    "        rect = plt.Rectangle((x, y), width, height, linewidth=2, edgecolor=edgecolor, facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "for ax, (_, row) in zip(axs, sample.iterrows()):\n",
    "    patient_id = row[\"patientId\"]\n",
    "    dcm_path = os.path.join(dataset_path, \"stage_2_train_images\", patient_id + ext)\n",
    "    ds = pydicom.dcmread(dcm_path)\n",
    "    ax.imshow(ds.pixel_array, cmap='gray')\n",
    "    ax.set_title(patient_id)\n",
    "    ax.axis('off')\n",
    "    if row[\"Target\"] == 1:\n",
    "         draw_bounding_box(ax, row[\"x\"], row[\"y\"], row[\"width\"], row[\"height\"])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data Splits to CSV Files\n",
    "\n",
    "This step persists our carefully prepared data splits to disk as CSV files in the `dataset_path` directory, the same location where our original dataset CSV resides. These files will serve as the foundation for our model training pipeline.\n",
    "\n",
    "Each split (training, validation, and test) is saved as a separate CSV file, preserving all columns from our DataFrames including patient IDs, class labels, and bounding box coordinates. The files maintain the same format as the original CSV, ensuring compatibility with existing data processing workflows. This standardized approach ensures reproducibility and simplifies dataset registration with Azure ML in subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write train, val and test DataFrames to CSV files in dataset_path\n",
    "train_df.to_csv(os.path.join(dataset_path, 'train.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(dataset_path, 'val.csv'), index=False)\n",
    "test_df.to_csv(os.path.join(dataset_path, 'test.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Data Assets with Azure Machine Learning\n",
    "\n",
    "This critical step transitions our locally prepared data into a properly registered Azure ML asset, making it accessible for distributed training jobs and ensuring reproducibility across experiments. By registering the dataset, we create a versioned reference that can be tracked, shared, and reused throughout the model development lifecycle.\n",
    "\n",
    "The registration process involves:\n",
    "\n",
    "- **Authentication**: Using Azure's DefaultAzureCredential to securely connect to the Azure ML workspace\n",
    "- **Data asset Definition**: Creating a Data entity with:\n",
    "  - A descriptive name (\"rsna_pneumonia_dataset\") for easy identification\n",
    "  - The path to our prepared dataset folder containing the original images and our custom split CSV files\n",
    "  - The type specification as \"uri_folder\" which preserves the directory structure\n",
    "  - A comprehensive description documenting the dataset's contents and purpose\n",
    "\n",
    "- **Version Management**: The `create_or_update` method ensures that if a dataset with this name already exists, it will be versioned rather than overwritten\n",
    "\n",
    "Once registered, this dataset becomes available through the Azure ML Studio interface and can be referenced by name in training scripts and job definitions. This centralized approach eliminates the need to repeatedly transfer large datasets between environments and ensures all team members work with identical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from workshop_helpers.utils import get_unique_name\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient.from_config(credential)\n",
    "\n",
    "unique_name = get_unique_name(credential)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "\n",
    "my_dataset = Data(\n",
    "    name=f\"rsna_pneumonia_dataset-{unique_name}\",\n",
    "    path=dataset_path,\n",
    "    type=\"uri_folder\",\n",
    "    description=\"RSNA Pneumonia detection dataset with custom data splits for train, val and test.\"\n",
    ")\n",
    "\n",
    "registered_dataset = ml_client.data.create_or_update(my_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Approach: Uploading Data to Blob Storage and Registering it as a Data Asset\n",
    "\n",
    "While this notebook demonstrates registering data from a local directory, many production ML workflows leverage data already stored in the cloud. Azure Blob Storage provides a scalable, secure foundation for storing and accessing large datasets across distributed training environments. This approach offers several significant advantages:\n",
    "\n",
    "- **Enterprise Scalability**: Blob Storage can efficiently handle terabytes of imaging data with high throughput access from multiple compute clusters\n",
    "- **Organizational Collaboration**: Teams can share consistent dataset versions without duplicating large files\n",
    "- **Cost Efficiency**: Eliminates redundant data transfers between environments and leverages Azure's tiered storage options\n",
    "- **Integration with Azure Ecosystem**: Seamlessly connects with other Azure services in your ML workflow\n",
    "\n",
    "This alternative workflow is particularly valuable when:\n",
    "- Your organization already maintains datasets in Azure Storage\n",
    "- Multiple teams or projects need access to the same medical imaging collections\n",
    "- You're working with datasets too large for practical local storage\n",
    "\n",
    "#### Implementation Steps:\n",
    "\n",
    "1. **Copy Data to Blob Storage using AzCopy**\n",
    "\n",
    "   The AzCopy utility provides optimized, resilient transfers between your local environment and Azure Storage. Simply execute:\n",
    "\n",
    "   ```bash\n",
    "   azcopy copy \"/path/to/local/data\" \"https://<storage_account>.blob.core.windows.net/<container>?<SAS_token>\" --recursive\n",
    "   ```\n",
    "\n",
    "2. **Register the Blob Storage Datastore**\n",
    "\n",
    "   Create a datastore reference that Azure ML can use to securely access your storage account:\n",
    "\n",
    "   ```python\n",
    "   from azure.ai.ml.entities import Datastore\n",
    "\n",
    "   blob_datastore = Datastore(\n",
    "         name=\"my_blob_datastore\",\n",
    "         account_name=\"<storage_account>\",\n",
    "         container_name=\"<container>\",\n",
    "         account_key=\"<your_storage_account_key>\",  # Or use SAS token for more granular access control\n",
    "         protocol=\"https\"\n",
    "   )\n",
    "\n",
    "   registered_blob_datastore = ml_client.datastores.create_or_update(blob_datastore)\n",
    "   print(f\"Datastore '{registered_blob_datastore.name}' registered.\")\n",
    "   ```\n",
    "\n",
    "3. **Create a Data Asset from the Registered Datastore Path**\n",
    "\n",
    "   Finally, define a data asset that references the specific path within your storage where the dataset resides:\n",
    "\n",
    "   ```python\n",
    "   from azure.ai.ml.entities import Data\n",
    "\n",
    "   data_asset = Data(\n",
    "         name=\"my_data_asset\",\n",
    "         path=\"azureml://datastores/my_blob_datastore/paths/path/to/data\",\n",
    "         type=\"uri_folder\",\n",
    "         description=\"RSNA Pneumonia detection dataset stored in Azure Blob Storage\"\n",
    "   )\n",
    "\n",
    "   registered_data_asset = ml_client.data.create_or_update(data_asset)\n",
    "   print(f\"Data asset '{registered_data_asset.name}' created.\")\n",
    "   ```\n",
    "\n",
    "This approach creates a layer of abstraction between your storage implementation and your ML code, allowing you to change underlying storage details without modifying your training scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
